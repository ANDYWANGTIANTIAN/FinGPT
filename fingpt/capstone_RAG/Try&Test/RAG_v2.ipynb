{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Implement RAG (langchain & Chroma) with base model LLama"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T14:46:07.972341Z","iopub.status.busy":"2024-05-26T14:46:07.971264Z","iopub.status.idle":"2024-05-26T14:46:08.924964Z","shell.execute_reply":"2024-05-26T14:46:08.923789Z","shell.execute_reply.started":"2024-05-26T14:46:07.972288Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["rm: cannot remove '/kaggle/working/chroma_db': No such file or directory\n"]}],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# Installations, imports, utils"]},{"cell_type":"code","execution_count":2,"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2024-05-26T14:46:08.927131Z","iopub.status.busy":"2024-05-26T14:46:08.926832Z","iopub.status.idle":"2024-05-26T14:49:01.971283Z","shell.execute_reply":"2024-05-26T14:49:01.970174Z","shell.execute_reply.started":"2024-05-26T14:46:08.927103Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting transformers==4.33.0\n","  Downloading transformers-4.33.0-py3-none-any.whl.metadata (119 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.9/119.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting accelerate==0.22.0\n","  Downloading accelerate-0.22.0-py3-none-any.whl.metadata (17 kB)\n","Collecting einops==0.6.1\n","  Downloading einops-0.6.1-py3-none-any.whl.metadata (12 kB)\n","Collecting langchain==0.0.300\n","  Downloading langchain-0.0.300-py3-none-any.whl.metadata (15 kB)\n","Collecting xformers==0.0.21\n","  Downloading xformers-0.0.21-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.0 kB)\n","Collecting bitsandbytes==0.41.1\n","  Downloading bitsandbytes-0.41.1-py3-none-any.whl.metadata (9.8 kB)\n","Collecting sentence_transformers==2.2.2\n","  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hCollecting chromadb==0.4.12\n","  Downloading chromadb-0.4.12-py3-none-any.whl.metadata (7.0 kB)\n","Collecting peft\n","  Downloading peft-0.11.1-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (0.22.2)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (2023.12.25)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (2.31.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.33.0)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (4.66.1)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.22.0) (5.9.3)\n","Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.22.0) (2.1.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (2.0.25)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (3.9.1)\n","Collecting anyio<4.0 (from langchain==0.0.300)\n","  Downloading anyio-3.7.1-py3-none-any.whl.metadata (4.7 kB)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (4.0.3)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (0.6.4)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (1.33)\n","Collecting langsmith<0.1.0,>=0.0.38 (from langchain==0.0.300)\n","  Downloading langsmith-0.0.92-py3-none-any.whl.metadata (9.9 kB)\n","Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (2.10.0)\n","Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (2.5.3)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (8.2.3)\n","Collecting torch>=1.10.0 (from accelerate==0.22.0)\n","  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n","Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (0.16.2)\n","Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (1.2.2)\n","Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (1.11.4)\n","Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (3.2.4)\n","Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (0.2.0)\n","Collecting pydantic<3,>=1 (from langchain==0.0.300)\n","  Downloading pydantic-1.10.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (150 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.6/150.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting chroma-hnswlib==0.7.3 (from chromadb==0.4.12)\n","  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n","Collecting fastapi<0.100.0,>=0.95.2 (from chromadb==0.4.12)\n","  Downloading fastapi-0.99.1-py3-none-any.whl.metadata (23 kB)\n","Requirement already satisfied: uvicorn>=0.18.3 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.12) (0.25.0)\n","Collecting posthog>=2.4.0 (from chromadb==0.4.12)\n","  Downloading posthog-3.5.0-py2.py3-none-any.whl.metadata (2.0 kB)\n","Requirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.12) (4.9.0)\n","Collecting pulsar-client>=3.1.0 (from chromadb==0.4.12)\n","  Downloading pulsar_client-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.0 kB)\n","Collecting onnxruntime>=1.14.1 (from chromadb==0.4.12)\n","  Downloading onnxruntime-1.18.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.3 kB)\n","Collecting pypika>=0.48.9 (from chromadb==0.4.12)\n","  Downloading PyPika-0.48.9.tar.gz (67 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n","\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n","\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: overrides>=7.3.1 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.12) (7.4.0)\n","Requirement already satisfied: importlib-resources in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.12) (6.1.1)\n","Collecting bcrypt>=4.0.1 (from chromadb==0.4.12)\n","  Downloading bcrypt-4.1.3-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n","Requirement already satisfied: typer>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.12) (0.9.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.22.0) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.22.0) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.22.0) (3.1.2)\n","Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch>=1.10.0->accelerate==0.22.0)\n","  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch>=1.10.0->accelerate==0.22.0)\n","  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch>=1.10.0->accelerate==0.22.0)\n","  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch>=1.10.0->accelerate==0.22.0)\n","  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu11==11.10.3.66 (from torch>=1.10.0->accelerate==0.22.0)\n","  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cufft-cu11==10.9.0.58 (from torch>=1.10.0->accelerate==0.22.0)\n","  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu11==10.2.10.91 (from torch>=1.10.0->accelerate==0.22.0)\n","  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch>=1.10.0->accelerate==0.22.0)\n","  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch>=1.10.0->accelerate==0.22.0)\n","  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu11==2.14.3 (from torch>=1.10.0->accelerate==0.22.0)\n","  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu11==11.7.91 (from torch>=1.10.0->accelerate==0.22.0)\n","  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Collecting triton==2.0.0 (from torch>=1.10.0->accelerate==0.22.0)\n","  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate==0.22.0) (69.0.3)\n","Requirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate==0.22.0) (0.42.0)\n","Collecting cmake (from triton==2.0.0->torch>=1.10.0->accelerate==0.22.0)\n","  Downloading cmake-3.29.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.1 kB)\n","Collecting lit (from triton==2.0.0->torch>=1.10.0->accelerate==0.22.0)\n","  Downloading lit-18.1.6-py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.300) (23.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.300) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.300) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.300) (1.4.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.300) (1.3.1)\n","Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<4.0->langchain==0.0.300) (3.6)\n","Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<4.0->langchain==0.0.300) (1.3.0)\n","Requirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio<4.0->langchain==0.0.300) (1.2.0)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.300) (3.21.1)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.300) (0.9.0)\n","Collecting starlette<0.28.0,>=0.27.0 (from fastapi<0.100.0,>=0.95.2->chromadb==0.4.12)\n","  Downloading starlette-0.27.0-py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.33.0) (2024.2.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain==0.0.300) (2.4)\n","Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb==0.4.12)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb==0.4.12) (23.5.26)\n","Requirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb==0.4.12) (3.20.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.33.0) (3.1.1)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb==0.4.12) (1.16.0)\n","Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb==0.4.12)\n","  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n","Requirement already satisfied: backoff>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb==0.4.12) (2.2.1)\n","Requirement already satisfied: python-dateutil>2.1 in /opt/conda/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb==0.4.12) (2.9.0.post0)\n","Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from pulsar-client>=3.1.0->chromadb==0.4.12) (2024.2.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.33.0) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.33.0) (1.26.18)\n","Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.300) (3.0.3)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer>=0.9.0->chromadb==0.4.12) (8.1.7)\n","Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb==0.4.12) (0.14.0)\n","Requirement already satisfied: httptools>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.12) (0.6.1)\n","Requirement already satisfied: python-dotenv>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.12) (1.0.0)\n","Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.12) (0.19.0)\n","Requirement already satisfied: watchfiles>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.12) (0.21.0)\n","Requirement already satisfied: websockets>=10.4 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.12) (12.0)\n","Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers==2.2.2) (1.4.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers==2.2.2) (3.2.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence_transformers==2.2.2) (9.5.0)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.300) (1.0.0)\n","Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.4.12)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.22.0) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.22.0) (1.3.0)\n","Downloading transformers-4.33.0-py3-none-any.whl (7.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading accelerate-0.22.0-py3-none-any.whl (251 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.2/251.2 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading einops-0.6.1-py3-none-any.whl (42 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain-0.0.300-py3-none-any.whl (1.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xformers-0.0.21-cp310-cp310-manylinux2014_x86_64.whl (167.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.0/167.0 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading bitsandbytes-0.41.1-py3-none-any.whl (92.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading chromadb-0.4.12-py3-none-any.whl (426 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.5/426.5 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hDownloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading peft-0.11.1-py3-none-any.whl (251 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading anyio-3.7.1-py3-none-any.whl (80 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.9/80.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading bcrypt-4.1.3-cp39-abi3-manylinux_2_28_x86_64.whl (283 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fastapi-0.99.1-py3-none-any.whl (58 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langsmith-0.0.92-py3-none-any.whl (56 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading onnxruntime-1.18.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pulsar_client-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m91.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hDownloading pydantic-1.10.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hDownloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m95.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n","Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading cmake-3.29.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading lit-18.1.6-py3-none-any.whl (96 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: sentence_transformers, pypika\n","  Building wheel for sentence_transformers (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=0748b373e4789a13d4e34dd6c3d00a0b46c62069c718f8f9bfa7756cb0e4901a\n","  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n","  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53724 sha256=d521344be6fca60d86fa3799a41379d524d46cfa82570d25b93b488eb8ddb1e9\n","  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n","Successfully built sentence_transformers pypika\n","Installing collected packages: tokenizers, pypika, monotonic, lit, bitsandbytes, pydantic, pulsar-client, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, humanfriendly, einops, cmake, chroma-hnswlib, bcrypt, anyio, starlette, posthog, nvidia-cusolver-cu11, nvidia-cudnn-cu11, langsmith, coloredlogs, transformers, onnxruntime, fastapi, langchain, chromadb, triton, torch, accelerate, xformers, sentence_transformers, peft\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.15.2\n","    Uninstalling tokenizers-0.15.2:\n","      Successfully uninstalled tokenizers-0.15.2\n","  Attempting uninstall: pydantic\n","    Found existing installation: pydantic 2.5.3\n","    Uninstalling pydantic-2.5.3:\n","      Successfully uninstalled pydantic-2.5.3\n","  Attempting uninstall: anyio\n","    Found existing installation: anyio 4.2.0\n","    Uninstalling anyio-4.2.0:\n","      Successfully uninstalled anyio-4.2.0\n","  Attempting uninstall: starlette\n","    Found existing installation: starlette 0.32.0.post1\n","    Uninstalling starlette-0.32.0.post1:\n","      Successfully uninstalled starlette-0.32.0.post1\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.39.3\n","    Uninstalling transformers-4.39.3:\n","      Successfully uninstalled transformers-4.39.3\n","  Attempting uninstall: fastapi\n","    Found existing installation: fastapi 0.108.0\n","    Uninstalling fastapi-0.108.0:\n","      Successfully uninstalled fastapi-0.108.0\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.1.2\n","    Uninstalling torch-2.1.2:\n","      Successfully uninstalled torch-2.1.2\n","  Attempting uninstall: accelerate\n","    Found existing installation: accelerate 0.29.3\n","    Uninstalling accelerate-0.29.3:\n","      Successfully uninstalled accelerate-0.29.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","jupyterlab 4.1.6 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n","jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n","kaggle-environments 1.14.3 requires transformers>=4.33.1, but you have transformers 4.33.0 which is incompatible.\n","ydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\n","ydata-profiling 4.6.4 requires pydantic>=2, but you have pydantic 1.10.15 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed accelerate-0.22.0 anyio-3.7.1 bcrypt-4.1.3 bitsandbytes-0.41.1 chroma-hnswlib-0.7.3 chromadb-0.4.12 cmake-3.29.3 coloredlogs-15.0.1 einops-0.6.1 fastapi-0.99.1 humanfriendly-10.0 langchain-0.0.300 langsmith-0.0.92 lit-18.1.6 monotonic-1.6 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 onnxruntime-1.18.0 peft-0.11.1 posthog-3.5.0 pulsar-client-3.5.0 pydantic-1.10.15 pypika-0.48.9 sentence_transformers-2.2.2 starlette-0.27.0 tokenizers-0.13.3 torch-2.0.1 transformers-4.33.0 triton-2.0.0 xformers-0.0.21\n"]}],"source":["!pip install transformers==4.33.0 accelerate==0.22.0 einops==0.6.1 langchain==0.0.300 xformers==0.0.21 \\\n","bitsandbytes==0.41.1 sentence_transformers==2.2.2 chromadb==0.4.12 peft"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":3,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2024-05-26T14:49:01.972909Z","iopub.status.busy":"2024-05-26T14:49:01.972631Z","iopub.status.idle":"2024-05-26T14:49:21.905030Z","shell.execute_reply":"2024-05-26T14:49:21.904272Z","shell.execute_reply.started":"2024-05-26T14:49:01.972883Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-05-26 14:49:11.020465: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-05-26 14:49:11.020563: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-05-26 14:49:11.154596: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["from torch import cuda, bfloat16\n","import torch\n","import transformers\n","from transformers import AutoTokenizer\n","from time import time\n","#import chromadb\n","#from chromadb.config import Settings\n","from langchain.llms import HuggingFacePipeline\n","from langchain.document_loaders import TextLoader\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain.embeddings import HuggingFaceEmbeddings\n","from langchain.chains import RetrievalQA\n","from langchain.vectorstores import Chroma\n","from peft import PeftModel\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["# Initialize model, tokenizer, query pipeline"]},{"cell_type":"markdown","metadata":{},"source":["Define the model, the device, and the `bitsandbytes` configuration."]},{"cell_type":"code","execution_count":4,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2024-05-26T14:49:21.907370Z","iopub.status.busy":"2024-05-26T14:49:21.907068Z","iopub.status.idle":"2024-05-26T14:49:21.914055Z","shell.execute_reply":"2024-05-26T14:49:21.913265Z","shell.execute_reply.started":"2024-05-26T14:49:21.907343Z"},"trusted":true},"outputs":[],"source":["model_id = 'meta-llama/Llama-2-7b-hf'\n","peft_model = 'Andy1124233/capstone_fingpt'\n","\n","device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n","\n","# set quantization configuration to load large model with less GPU memory\n","# this requires the `bitsandbytes` library\n","bnb_config = transformers.BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_quant_type='nf4',\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_compute_dtype=bfloat16\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Prepare the model and the tokenizer."]},{"cell_type":"code","execution_count":5,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2024-05-26T14:49:21.915849Z","iopub.status.busy":"2024-05-26T14:49:21.915349Z","iopub.status.idle":"2024-05-26T14:50:46.539186Z","shell.execute_reply":"2024-05-26T14:50:46.538289Z","shell.execute_reply.started":"2024-05-26T14:49:21.915818Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"578f7d2f2b1249cbac56804d259528da","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/609 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a3b6f53edb464706936dfa69f28528bb","version_major":2,"version_minor":0},"text/plain":["model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"37dfb356c47e4b21b622add60671091d","version_major":2,"version_minor":0},"text/plain":["Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dae31107462042eba0b8bfef8cf150f5","version_major":2,"version_minor":0},"text/plain":["model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2888ccae90a14491a29c9e24ee78fa49","version_major":2,"version_minor":0},"text/plain":["model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dd663ce03b0e4aa486d117c3da3037d5","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:374: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"189b622590824d2a916ce7a7a6f3663d","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"af64bca8401a4efbbf205c6bc0c4eece","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/776 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"810f11faec824d119c6b6a7cd158f9f5","version_major":2,"version_minor":0},"text/plain":["tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5b8ab2da9c284873b7caa507f972f4d6","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"479aeb634aeb4a9ab31bd3a8a0c636ac","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"746fe472acc74667b9cb750240156f19","version_major":2,"version_minor":0},"text/plain":["adapter_config.json:   0%|          | 0.00/663 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5f52cad1d9104c6aa821a1047a91041b","version_major":2,"version_minor":0},"text/plain":["adapter_model.safetensors:   0%|          | 0.00/12.6M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Prepare model, tokenizer: 84.459 sec.\n"]}],"source":["time_1 = time()\n","hf_auth=\"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\"\n","\n","model_config = transformers.AutoConfig.from_pretrained(\n","    model_id,\n","    token=hf_auth\n",")\n","model = transformers.AutoModelForCausalLM.from_pretrained(\n","    model_id,\n","    trust_remote_code=True,\n","    quantization_config=bnb_config,\n","    device_map='auto',\n","    token=hf_auth\n","\n","    \n",")\n","tokenizer = AutoTokenizer.from_pretrained(model_id,token=hf_auth)\n","model = PeftModel.from_pretrained(model, peft_model)\n","model = model.eval()\n","\n","time_2 = time()\n","print(f\"Prepare model, tokenizer: {round(time_2-time_1, 3)} sec.\")"]},{"cell_type":"markdown","metadata":{},"source":["Define the query pipeline."]},{"cell_type":"code","execution_count":6,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2024-05-26T14:50:46.540495Z","iopub.status.busy":"2024-05-26T14:50:46.540203Z","iopub.status.idle":"2024-05-26T14:50:48.116648Z","shell.execute_reply":"2024-05-26T14:50:48.115757Z","shell.execute_reply.started":"2024-05-26T14:50:46.540470Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"]},{"name":"stdout","output_type":"stream","text":["Prepare pipeline: 1.571 sec.\n"]}],"source":["time_1 = time()\n","query_pipeline = transformers.pipeline(\n","        \"text-generation\",\n","        model=model,\n","        tokenizer=tokenizer,\n","        torch_dtype=torch.float16,\n","        device_map=\"auto\",)\n","time_2 = time()\n","print(f\"Prepare pipeline: {round(time_2-time_1, 3)} sec.\")"]},{"cell_type":"markdown","metadata":{},"source":["We define a function for testing the pipeline."]},{"cell_type":"code","execution_count":7,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2024-05-26T14:50:48.118150Z","iopub.status.busy":"2024-05-26T14:50:48.117883Z","iopub.status.idle":"2024-05-26T14:50:48.124180Z","shell.execute_reply":"2024-05-26T14:50:48.123253Z","shell.execute_reply.started":"2024-05-26T14:50:48.118126Z"},"trusted":true},"outputs":[],"source":["def test_model(tokenizer, pipeline, prompt_to_test):\n","    \"\"\"\n","    Perform a query\n","    print the result\n","    Args:\n","        tokenizer: the tokenizer\n","        pipeline: the pipeline\n","        prompt_to_test: the prompt\n","    Returns\n","        None\n","    \"\"\"\n","    # adapted from https://huggingface.co/blog/llama2#using-transformers\n","    time_1 = time()\n","    sequences = pipeline(\n","        prompt_to_test,\n","        do_sample=True,\n","        top_k=10,\n","        num_return_sequences=1,\n","        eos_token_id=tokenizer.eos_token_id,\n","        max_length=200,)\n","    time_2 = time()\n","    print(f\"Test inference: {round(time_2-time_1, 3)} sec.\")\n","    for seq in sequences:\n","        print(f\"Result: {seq['generated_text']}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Test the query pipeline\n","\n","We test the pipeline with a query about the meaning of State of the Union (SOTU)."]},{"cell_type":"code","execution_count":8,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2024-05-26T14:50:48.125777Z","iopub.status.busy":"2024-05-26T14:50:48.125517Z","iopub.status.idle":"2024-05-26T14:51:10.046658Z","shell.execute_reply":"2024-05-26T14:51:10.045729Z","shell.execute_reply.started":"2024-05-26T14:50:48.125755Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Test inference: 21.908 sec.\n","Result: Please explain what is the State of the Union address. Give just a definition. Keep it in 100 words.  P, P,, information Unterscheidung Hinweis sierp Unterscheidung everybody hopefully nobody nobody Hinweis hopefully Hinweis nobody nobody nobody nobody nobody.is,, everybody фев Unterscheidung февch/ M Hinweis P Hinweis,-y Hinweis ( and kwiet,c hopefully everybody фев nobody Unterscheidung sierp Hinweis Hinweis Hinweis nobody nobody A g\n"," everybody  A. Hinweis nobody nobody, a фев фев Hinweis everybody everybody hopefully nobody everybody nobody nobody nobody w \n"," kwiet t nobody фев фев nobody nobody everybody,  nobody Hinweis sierp,,äufig, nobody everybody kwiet Hinweis nobody nobody nobody Unterscheidung nobody everybody nobody nobody nobody nobody everybody everybody nobody nobody nobody Unterscheidung everybody nobody sierpc Hinweis,, hopefully nobody hopefully everybody everybody, nobody limitedc nobody hopefullyө. nobody nobody nobody everybody nobody everybody nobody nobody everybodyz nobody nobody everybody. Hinweis, and,\n","..,,,. kwiet paździer,, (.\n"]}],"source":["test_model(tokenizer,\n","           query_pipeline,\n","           \"Please explain what is the State of the Union address. Give just a definition. Keep it in 100 words.\")"]},{"cell_type":"markdown","metadata":{},"source":["# Retrieval Augmented Generation"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2023-09-23T19:22:16.434937Z","iopub.status.busy":"2023-09-23T19:22:16.433666Z","iopub.status.idle":"2023-09-23T19:22:16.440864Z","shell.execute_reply":"2023-09-23T19:22:16.439217Z","shell.execute_reply.started":"2023-09-23T19:22:16.434891Z"}},"source":["## Check the model with a HuggingFace pipeline\n","\n","\n","We check the model with a HF pipeline, using a query about the meaning of State of the Union (SOTU)."]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2024-05-26T14:51:10.048191Z","iopub.status.busy":"2024-05-26T14:51:10.047906Z"},"trusted":true},"outputs":[],"source":["llm = HuggingFacePipeline(pipeline=query_pipeline)\n","# checking again that everything is working fine\n","llm(prompt=\"What is the Apple.Inc's revenue in quarter of March in 2024?\")"]},{"cell_type":"markdown","metadata":{},"source":["## Ingestion of data using Text loder\n","\n","We will ingest the newest presidential address, from Jan 2023."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["text = '''Today Apple is reporting revenue of $90.8 billion for the March quarter in 2024, including an all-time revenue record in Services. During the quarter, we were thrilled to launch Apple Vision Pro and to show the world the potential that spatial computing unlocks. We’re also looking forward to an exciting product announcement next week and an incredible Worldwide Developers Conference next month. As always, we are focused on providing the very best products and services for our customers, and doing so while living up to the core values that drive us.'''\n","\n","# Specify the file path\n","\n","def convert_file(text,name):\n","    file_path = name+'.txt'\n","\n","    # Write the text to the file\n","    with open(file_path, 'w', encoding='utf-8') as file:\n","        file.write(text)\n","\n","    print(f\"The text has been stored in the file: {file_path}\")\n","    \n","text1='''CUPERTINO, CALIFORNIA Apple today announced financial results for its fiscal 2024 first quarter ended December 30, 2023. The Company posted quarterly revenue of $119.6 billion, up 2 percent year over year, and quarterly earnings per diluted share of $2.18, up 16 percent year over year.\n","“Today Apple is reporting revenue growth for the December quarter fueled by iPhone sales, and an all-time revenue record in Services,” said Tim Cook, Apple’s CEO. “We are pleased to announce that our installed base of active devices has now surpassed 2.2 billion, reaching an all-time high across all products and geographic segments. And as customers begin to experience the incredible Apple Vision Pro tomorrow, we are committed as ever to the pursuit of groundbreaking innovation — in line with our values and on behalf of our customers.”\n","“Our December quarter top-line performance combined with margin expansion drove an all-time record EPS of $2.18, up 16 percent from last year,” said Luca Maestri, Apple’s CFO. “During the quarter, we generated nearly $40 billion of operating cash flow, and returned almost $27 billion to our shareholders. We are confident in our future, and continue to make significant investments across our business to support our long-term growth plans.”\n","Apple’s board of directors has declared a cash dividend of $0.24 per share of the Company’s common stock. The dividend is payable on February 15, 2024 to shareholders of record as of the close of business on February 12, 2024.\n","Based on the Company’s fiscal calendar, the Company’s fiscal 2024 first quarter had 13 weeks, while the Company’s fiscal 2023 first quarter had 14 weeks.\n","Apple will provide live streaming of its Q1 2024 financial results conference call beginning at 2:00 p.m. PT on February 1, 2024 at apple.com/investor/earnings-call. The webcast will be available for replay for approximately two weeks thereafter.'''\n","\n","text2='''Earnings Release FY24 Q2\n","Microsoft Cloud Strength Drives Second Quarter Results\n","\n","REDMOND, Wash. — January 30, 2024 — Microsoft Corp. today announced the following results for the quarter ended December 31, 2023, as compared to the corresponding period of last fiscal year:\n","\n","·        Revenue was $62.0 billion and increased 18% (up 16% in constant currency)\n","\n","·        Operating income was $27.0 billion and increased 33%, and increased 25% non-GAAP (up 23% in constant currency)\n","\n","·        Net income was $21.9 billion and increased 33%, and increased 26% non-GAAP (up 23% in constant currency)\n","\n","·        Diluted earnings per share was $2.93 and increased 33%, and increased 26% non-GAAP (up 23% in constant currency)\n","\n","Microsoft completed the acquisition of Activision Blizzard, Inc. (“Activision”) on October 13, 2023. Financial results from the acquired business are reported in the More Personal Computing segment.\n","\n","\"We’ve moved from talking about AI to applying AI at scale,\" said Satya Nadella, chairman and chief executive officer of Microsoft. \"By infusing AI across every layer of our tech stack, we’re winning new customers and helping drive new benefits and productivity gains across every sector.”\n","\n","“Strong execution by our sales teams and partners drove Microsoft Cloud revenue to $33.7 billion, up 24% (up 22% in constant currency) year-over-year,” said Amy Hood, executive vice president and chief financial officer of Microsoft.\n","\n","The following table reconciles our financial results reported in accordance with generally accepted accounting principles (GAAP) to non-GAAP financial results. Additional information regarding our non-GAAP definition is provided below. All growth comparisons relate to the corresponding period in the last fiscal year.'''\n","text3='''SEATTLE--(BUSINESS WIRE)-- Starbucks Corporation (Nasdaq: SBUX) today reported financial results for its 13-week fiscal second quarter ended March 31, 2024. GAAP results in fiscal 2024 and fiscal 2023 include items that are excluded from non-GAAP results. Please refer to the reconciliation of GAAP measures to non-GAAP measures at the end of this release for more information.\n","\n","Q2 Fiscal 2024 Highlights\n","\n","Global comparable store sales declined 4%, driven by a 6% decline in comparable transactions, partially offset by a 2% increase in average ticket\n","North America and U.S. comparable store sales declined 3%, driven by a 7% decline in comparable transactions, partially offset by a 4% increase in average ticket\n","International comparable store sales declined 6%, driven by a 3% decline in both comparable transactions and average ticket; China comparable store sales declined 11%, driven by an 8% decline in average ticket and a 4% decline in comparable transactions\n","The company opened 364 net new stores in Q2, ending the period with 38,951 stores: 52% company-operated and 48% licensed\n","At the end of Q2, stores in the U.S. and China comprised 61% of the company’s global portfolio, with 16,600 and 7,093 stores in the U.S. and China, respectively\n","Consolidated net revenues declined 2%, to $8.6 billion, or a 1% decline on a constant currency basis\n","GAAP operating margin contracted 240 basis points year-over-year to 12.8%, primarily driven by deleverage, incremental investments in store partner wages and benefits, increased promotional activities, lapping the gain on the sale of Seattle's Best Coffee brand, as well as higher general and administrative costs primarily in support of Reinvention. This decline was partially offset by pricing and in-store operational efficiencies.\n","Non-GAAP operating margin contracted 150 basis points year-over-year to 12.8%, or contracted 140 basis points on a constant currency basis\n","GAAP earnings per share of $0.68 declined 14% over prior year\n","Non-GAAP earnings per share of $0.68 declined 8% over prior year, or declined 7% on a constant currency basis\n","Starbucks Rewards loyalty program 90-day active members in the U.S. totaled 32.8 million, up 6% year-over-year\n","“In a highly challenged environment, this quarter's results do not reflect the power of our brand, our capabilities or the opportunities ahead,” commented Laxman Narasimhan, chief executive officer. “It did not meet our expectations, but we understand the specific challenges and opportunities immediately in front of us. We have a clear plan to execute and the entire organization is mobilized around it. We are very confident in our long-term and know that our Triple Shot Reinvention with Two Pumps strategy will deliver on the limitless potential of this brand,” Narasimhan added.\n","\n","“While it was a difficult quarter, we learned from our own underperformance and sharpened our focus with a comprehensive roadmap of well thought out actions making the path forward clear,” commented Rachel Ruggeri, chief financial officer. “On this path, we remain committed to our disciplined approach to capital allocation as we navigate this complex and dynamic environment,” Ruggeri added.'''\n","convert_file(text,\"2nd_Apple\")\n","convert_file(text1,\"1nd_Apple\")\n","convert_file(text2,\"1nd_Microsoft\")\n","convert_file(text3,\"2nd_Starbucks\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## Split data in chunks\n","\n","We split data in chunks using a recursive character text splitter."]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## Creating Embeddings and Storing in Vector Store"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["Create the embeddings using Sentence Transformer and HuggingFace embeddings."]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["import glob\n","vectordb = Chroma(\n","   \n","    embedding_function=embeddings\n",")\n","\n","# Specify the folder path where the .txt files are located\n","folder_path = \"/kaggle/working/\"\n","\n","# Use glob to get the list of .txt files in the folder\n","txt_files = glob.glob(folder_path + \"/*.txt\")\n","\n","for i in txt_files:\n","    loader = TextLoader(i,\n","                        encoding=\"utf8\")\n","    documents = loader.load()\n","    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n","    all_splits = text_splitter.split_documents(documents)\n","    model_name = \"sentence-transformers/all-mpnet-base-v2\"\n","    model_kwargs = {\"device\": \"cuda\"}\n","    embeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)\n","    vectordb = Chroma.from_documents(documents=all_splits, embedding=embeddings, persist_directory=\"chroma_db\")"]},{"cell_type":"markdown","metadata":{},"source":["Initialize ChromaDB with the document splits, the embeddings defined previously and with the option to persist it locally."]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## Initialize chain"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["retriever = vectordb.as_retriever()\n","\n","qa = RetrievalQA.from_chain_type(\n","    llm=llm, \n","    chain_type=\"stuff\", \n","    retriever=retriever, \n","    verbose=True\n",")"]},{"cell_type":"markdown","metadata":{},"source":["## Test the Retrieval-Augmented Generation \n","\n","\n","We define a test function, that will run the query and time it."]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["def test_rag(qa, query):\n","    print(f\"Query: {query}\\n\")\n","    time_1 = time()\n","    result = qa.run(query)\n","    time_2 = time()\n","    print(f\"Inference time: {round(time_2-time_1, 3)} sec.\")\n","    print(\"\\nResult: \", result)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["llm(prompt=\"What is the Apple.Inc's revenue gap between recent continous quarters ?\")"]},{"cell_type":"markdown","metadata":{},"source":["Let's check few queries."]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["print(\"------------------------------RAG-------------------------------------------\")\n","query = \"What is the Apple.Inc's revenue gap between recent continous quarter ?\"\n","test_rag(qa, query)"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["query = \"What is the revenue for last quarter at Apple.Inc in 2023?\"\n","test_rag(qa, query)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["query = \"What is the relationship between Microsoft, Apple.Inc and Starbuck ?\"\n","test_rag(qa, query)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["llm(prompt=query)"]},{"cell_type":"markdown","metadata":{},"source":["## Document sources\n","\n","Let's check the documents sources, for the last query run."]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["docs = vectordb.similarity_search(query)\n","print(f\"Query: {query}\")\n","print(f\"Retrieved documents: {len(docs)}\")\n","for doc in docs:\n","    doc_details = doc.to_json()['kwargs']\n","    print(\"Source: \", doc_details['metadata']['source'])\n","    print(\"Text: \", doc_details['page_content'], \"\\n\")"]},{"cell_type":"markdown","metadata":{},"source":["# Conclusions\n","\n","\n","We used Langchain, ChromaDB and Llama 2 as a LLM to build a Retrieval Augmented Generation solution. For testing, we were using the latest State of the Union address from Jan 2023.\n","\n","\n","# More work on the same topic\n","\n","You can find more details about how to use a LLM with Kaggle. Few interesting topics are treated in:  \n","\n","* https://www.kaggle.com/code/gpreda/test-llama-2-quantized-with-llama-cpp (quantizing LLama 2 model using llama.cpp)\n","* https://www.kaggle.com/code/gpreda/fast-test-of-llama-v2-pre-quantized-with-llama-cpp  (quantized Llamam 2 model using llama.cpp)  \n","* https://www.kaggle.com/code/gpreda/test-of-llama-2-quantized-with-llama-cpp-on-cpu (quantized model using llama.cpp - running on CPU)  \n","* https://www.kaggle.com/code/gpreda/explore-enron-emails-with-langchain-and-llama-v2 (Explore Enron Emails with Langchain and Llama v2)\n"]},{"cell_type":"markdown","metadata":{},"source":["# References  \n","\n","[1] Murtuza Kazmi, Using LLaMA 2.0, FAISS and LangChain for Question-Answering on Your Own Data, https://medium.com/@murtuza753/using-llama-2-0-faiss-and-langchain-for-question-answering-on-your-own-data-682241488476  \n","\n","[2] Patrick Lewis, Ethan Perez, et. al., Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks, https://browse.arxiv.org/pdf/2005.11401.pdf \n","\n","[3] Minhajul Hoque, Retrieval Augmented Generation: Grounding AI Responses in Factual Data, https://medium.com/@minh.hoque/retrieval-augmented-generation-grounding-ai-responses-in-factual-data-b7855c059322  \n","\n","[4] Fangrui Liu\t, Discover the Performance Gain with Retrieval Augmented Generation, https://thenewstack.io/discover-the-performance-gain-with-retrieval-augmented-generation/\n","\n","[5] Andrew, How to use Retrieval-Augmented Generation (RAG) with Llama 2, https://agi-sphere.com/retrieval-augmented-generation-llama2/   \n","\n","[6] Yogendra Sisodia, Retrieval Augmented Generation Using Llama2 And Falcon, https://medium.com/@scholarly360/retrieval-augmented-generation-using-llama2-and-falcon-ed26c7b14670   \n","\n"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"modelInstanceId":3093,"sourceId":4298,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
