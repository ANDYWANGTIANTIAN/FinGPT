# Data Preparation For Capstone Project

We will have three category data for our Llama fine-tuning 


- Data from FinGPT 

- Other source from hugging face

  - [ChanceFocus/flare-cfa](https://huggingface.co/datasets/ChanceFocus/flare-cfa)
  - [jan-hq/finqa_bench_stealth-finance-v3](https://huggingface.co/datasets/jan-hq/finqa_bench_stealth-finance-v3?row=36)

- Data Extracted from our own (Question generated by gpt-3.5-turbo :robot:)

  - :books: [CFA textbook, ](https://page.sapp.edu.vn/hubfs/T%C3%A0i%20li%E1%BB%87u%20CFA%20Level%201/Secret%20Sauce%20CFA%20Level%201.pdf)  --- cover profolio management, equity investment, derivatives, financial statement, fixed income. 
  - Macro research paper (From Bloomberg) --- will finish on May 21:see_no_evil:
    - 10 report (total ~1000 record )
  - Equity research report (From Bloomberg) -- will finish on May 21 :see_no_evil:
    - 10 companies (total ~100 record)

  

  

  

  

  ## Reference

  - Text split technique: 
    - [Multi-modal Text spliter](https://github.com/langchain-ai/langchain/blob/master/cookbook/Multi_modal_RAG.ipynb)
    - [Unstructured file Text splitter](https://python.langchain.com/v0.1/docs/integrations/document_loaders/unstructured_file/)

  - Azure openai api:

    - [Guide for connect](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/switching-endpoints)

    



